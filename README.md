# AdVisor

> AI-powered ad creative analysis platform using 932 diverse persona agents to provide authentic audience feedback

## üéØ Overview

AdVisor empowers marketers to understand and improve their ad creatives by combining multimodal feature extraction with generative agent simulations. The platform analyzes ads through the lens of 932 unique, data-driven personas sourced from real Reddit communities, providing authentic feedback on how different audience segments perceive creative content.

## üèóÔ∏è Architecture

```
User Application
     ‚Üì
Agentverse Coordinator Agent (SupaVisor)
     ‚Üì
AWS EC2 FastAPI Server (52.53.159.105:8000)
     ‚Üì
932 Persona Agents (Supabase + pgvector)
     ‚Üì
Fetch.ai ASI:One API (asi1-mini model)
```

## üîß Technology Stack

### Backend
- **FastAPI** - High-performance Python web framework for API endpoints
- **Python 3.12** - Core programming language
- **uvicorn** - ASGI server for production deployment

### AI & Agent Framework
- **Fetch.ai ASI:One API** - AI reasoning engine (asi1-mini model) for authentic persona embodiment
- **uAgents Framework** - Official Fetch.ai framework for agent creation and communication
- **Agentverse** - Fetch.ai's platform for hosting and discovering agents
- **OpenAI API** - GPT-4o-mini for persona generation, text-embedding-3-small for embeddings

### Database & Vector Search
- **Supabase** - PostgreSQL database with built-in APIs
- **pgvector** - PostgreSQL extension for vector similarity search
- **IVFFlat indexing** - Fast k-NN search for persona/content embeddings

### Data Collection
- **Bright Data Dataset API** - Reddit scraping for community data
  - Keyword-based discovery (101 keywords)
  - URL-based comment extraction (1,508 posts)
  - Multi-community analysis (1,577 communities)

### Deployment & Infrastructure
- **AWS EC2** - Cloud hosting (Amazon Linux)
- **Docker & Docker Compose** - Containerization for consistent deployment
- **systemd** - Service management for auto-restart
- **Git** - Version control

### Development Tools
- **python-dotenv** - Environment variable management
- **requests** - HTTP client for API communication
- **Pydantic** - Data validation and settings management
- **dateparser** - Flexible date parsing

## üìä System Components

### 1. Ad Upload & Processing
- Upload ad creatives (image/video) with company metadata
- Extract raw files and metadata for analysis

### 2. Feature Extraction Engine
- **Goal**: Extract ‚â•10 distinct, decorrelated features per ad
- **Performance**: <5 min per 50 ads on single GPU
- Multimodal analysis: visual, text, audio, sentiment

### 3. Feature Store
- Centralized structured dataset
- Vector embeddings (1536 dimensions via OpenAI)
- Efficient similarity search

### 4. Community Recommender
- Suggests best-fit audience communities to simulate
- Routes analysis to relevant persona demographics

### 5. Agent Simulation Layer ‚≠ê **CORE COMPONENT**
- **932 unique personas** generated from real Reddit community data
- Each persona has:
  - Demographics (age, location, income, education, occupation)
  - Psychographics (values, interests, lifestyle)
  - Pain points and motivations
  - Authentic community context
- Personas embodied by Fetch.ai ASI:One AI for realistic responses
- Types: Performance Analyst, Creative Director, Community Member

### 6. Creative Feedback & Variant Generator
- Aggregates persona analyses
- Sentiment breakdown (positive/neutral/negative)
- Actionable recommendations
- Creative improvement suggestions

### 7. Insights Dashboard
- Visualization of aggregated feedback
- Sentiment distribution
- Export capabilities for marketers

## üöÄ Getting Started

### Prerequisites
```bash
Python 3.12+
PostgreSQL with pgvector extension
Docker & Docker Compose (for deployment)
```

### Environment Variables
Create a `.env` file in the project root:
```bash
# Fetch.ai Configuration
FETCH_AI_API_KEY=sk_...
AGENTVERSE_KEY=eyJhbGc...
AGENT_SEED_PHRASE=your_seed_phrase_here

# Supabase Database
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=eyJhbGc...

# OpenAI API
OPENAI_API_KEY=sk-proj-...

# Bright Data (Reddit Scraping)
BRIGHT_DATA_API_KEY=...
```

### Local Development

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/AdVisor.git
   cd AdVisor
   ```

2. **Install dependencies**
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

3. **Set up Supabase database**
   ```bash
   # Run SQL schemas in Supabase SQL Editor
   backend/sql/01_knowledge_graph_schema.sql
   backend/sql/02_vector_database_schema.sql
   ```

4. **Process Reddit data and generate personas** (optional - already done)
   ```bash
   python backend/db/process_reddit_data.py
   # Processes 1,577 communities, generates 1,000 personas
   # Cost: ~$3.85, Time: ~60-75 minutes
   ```

5. **Run the API server**
   ```bash
   cd backend
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

6. **Test the API**
   ```bash
   curl http://localhost:8000/agents/personas
   ```

### AWS Deployment

See detailed guide: [`backend/deploy/AWS_DEPLOYMENT.md`](backend/deploy/AWS_DEPLOYMENT.md)

```bash
# On AWS EC2 instance
cd AdVisor/backend
docker-compose up -d
```

**Live Production API**: http://52.53.159.105:8000

### Agentverse Coordinator Deployment

See detailed guide: [`backend/AGENTVERSE_WEB_DEPLOY.md`](backend/AGENTVERSE_WEB_DEPLOY.md)

1. Go to https://agentverse.ai
2. Create new agent
3. Copy code from `backend/agents/COPY_THIS_TO_AGENTVERSE.py`
4. Deploy and get agent address

## üì° API Endpoints

### Core Endpoints

#### **GET** `/agents/personas`
List all 932 personas with demographics and psychographics
```json
[
  {
    "id": "uuid",
    "name": "Socially-Conscious Teens 18-24",
    "demographics": {...},
    "psychographics": {...}
  }
]
```

#### **POST** `/agents/chat`
Chat with a specific persona
```json
{
  "persona_id": "uuid",
  "message": "What do you think about this ad?"
}
```

#### **POST** `/agents/analyze-ad`
Get single persona's analysis of an ad
```json
{
  "persona_id": "uuid",
  "ad_description": "Nike running shoes ad featuring athlete..."
}
```

#### **POST** `/agents/analyze-ad-multi`
Get multi-persona analysis (recommended)
```json
{
  "ad_description": "Nike running shoes ad...",
  "num_personas": 10
}
```
**Response**: Array of analyses + sentiment summary

#### **POST** `/agents/{persona_id}/context`
Get persona's relevant context via vector search

#### **POST** `/agents/similar`
Find similar personas via embedding similarity

## üìà Key Metrics & Performance

| Metric | Value |
|--------|-------|
| Total Personas | 932 |
| Source Communities | 1,577 Reddit communities |
| Scraped Posts | 10,043+ |
| Persona Generation Cost | $2.00 (OpenAI GPT-4o-mini) |
| Embedding Cost | $0.05 (text-embedding-3-small) |
| Vector Dimensions | 1,536 |
| API Response Time | <5s for 10 personas |
| Database Size | ~8 MB (personas + embeddings) |
| Similarity Search | <100ms (IVFFlat index) |

## üéØ Key Objectives

| Goal | Description | Metric |
|------|-------------|--------|
| Feature Extraction Insight | Extract semantically rich, non-redundant signals | ‚â•10 distinct features per ad |
| Performance | Fast processing, parallelizable | <5 min per 50 ads |
| Robustness | Handle diverse industries, formats | 100% of .png/.mp4 ads |
| Creativity | Unique, interpretable signals | ‚â•3 novel signal types |
| Authenticity | Real persona responses | 932 data-driven personas |

## üß™ Example Usage

### Python Client
```python
import requests

# Analyze ad with 10 diverse personas
response = requests.post(
    "http://52.53.159.105:8000/agents/analyze-ad-multi",
    json={
        "ad_description": "Eco-friendly water bottle ad. Shows hikers in nature. Tagline: 'Hydrate Responsibly.'",
        "num_personas": 10
    }
)

analyses = response.json()

# Get sentiment breakdown
for analysis in analyses:
    print(f"{analysis['persona_name']}: {analysis['sentiment']}")
    print(f"  Reasoning: {analysis['reasoning'][:100]}...")
```

### Agentverse Agent Communication
```python
from uagents import Agent, Context, Model

class AdAnalysisRequest(Model):
    ad_description: str
    num_personas: int = 10

# Send to coordinator on Agentverse
await ctx.send(
    "agent1q...",  # Coordinator address
    AdAnalysisRequest(
        ad_description="Your ad here",
        num_personas=5
    )
)
```

## üìÇ Project Structure

```
AdVisor/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                          # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona_agent.py             # Persona agent with Fetch.ai integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ coordinator_agent.py         # Local coordinator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ COPY_THIS_TO_AGENTVERSE.py   # Agentverse deployment code
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deploy_to_agentverse.py      # Registration script
‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persona_manager.py           # Persona CRUD operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_graph.py           # Community/interest graph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py              # pgvector operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ process_reddit_data.py       # Data processing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_knowledge_graph_schema.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 02_vector_database_schema.sql
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetchai_client.py            # Fetch.ai ASI:One wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai_client.py             # OpenAI API wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py           # Supabase connection
‚îÇ   ‚îú‚îÄ‚îÄ deploy/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AWS_DEPLOYMENT.md
‚îÇ   ‚îú‚îÄ‚îÄ data/                            # Scraped Reddit data (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env                                 # Environment variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ CLAUDE.md                            # Project development log
‚îî‚îÄ‚îÄ README.md                            # This file
```

## üîê Security Notes

- All API keys stored in `.env` (not committed to git)
- AWS EC2 security groups configured for ports 22, 80, 8000
- Supabase Row Level Security (RLS) policies active
- Agent seed phrases for cryptographic signatures

## üåü Unique Features

### 1. **Real Data-Driven Personas**
Unlike traditional simulated personas, AdVisor's 932 agents are generated from real Reddit community data, ensuring authentic perspectives.

### 2. **Distributed Agent Architecture**
- Coordinator agent on Agentverse for orchestration
- 932 persona agents on AWS for scalability
- Fetch.ai ASI:One for reasoning

### 3. **Multi-Community Analysis**
Each persona represents a unique community segment with:
- Specific demographics
- Real pain points from Reddit posts
- Authentic motivations and values

### 4. **Fast Vector Search**
pgvector with IVFFlat indexing enables <100ms similarity search across 932 persona embeddings

### 5. **Flexible Deployment**
- Local development
- AWS EC2 production
- Agentverse coordinator
- Docker containerization

## üìä Data Pipeline

```
Bright Data Reddit Scraping
     ‚Üì
10,043 posts from 1,577 communities
     ‚Üì
Keyword extraction + community analysis
     ‚Üì
GPT-4o-mini persona generation (50 per community)
     ‚Üì
OpenAI embeddings (1536 dimensions)
     ‚Üì
Supabase + pgvector storage
     ‚Üì
932 Persona Agents powered by Fetch.ai
```

## üõ£Ô∏è Roadmap

- [ ] Complete Feature Extraction Engine (Component 2)
- [ ] Set up Feature Store for ad embeddings (Component 3)
- [ ] Build Community Recommender (Component 4)
- [ ] Implement Creative Feedback & Variant Generator (Component 6)
- [ ] Create Insights Dashboard (Component 7)
- [ ] Add image/video multimodal analysis
- [ ] Implement HTTPS with Nginx
- [ ] Add API authentication
- [ ] Build frontend application

## ü§ù Contributing

This project is under active development. Contributions welcome!

## üìù License

MIT License - See LICENSE file for details

## üë§ Author

Built by Sharan S.

## üôè Acknowledgments

- **Fetch.ai** - ASI:One API and uAgents framework
- **Supabase** - Database and vector search infrastructure
- **OpenAI** - Persona generation and embeddings
- **Bright Data** - Reddit data collection
- **Reddit Communities** - Source data for authentic personas

---

**Status**: Production Ready ‚úÖ
- AWS Deployment: Live at http://52.53.159.105:8000
- 932 Personas: Active and responding
- Agentverse Coordinator: Ready for deployment

For questions or issues, please open a GitHub issue or contact the maintainer.
